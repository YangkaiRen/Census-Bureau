{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from itertools import combinations\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = [\"age\", \"workClass\", \"fnlwgt\", \"education\", \"education.num\",\n",
    "                \"marital.status\", \"occupation\", \"relationship\", \"race\", \"sex\", \n",
    "                \"capital_gain\", \"capital_loss\", \"hours_perweek\", \"native_country\", \"income\"]\n",
    "\n",
    "train_df = pd.read_csv('../data/adult.data', names=columns_name, sep=' *, *')\n",
    "test_df = pd.read_csv('../data/adult.test',  names=columns_name, sep=' *, *', skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------preprocessing--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. concate train_df and test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_df.drop('income', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_df, test_X], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Explaced formate error \"?\" to be None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df == '?'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The dependent column ‘income’ which is to be predicted has been replaced with 0 and 1 and hence convert the problem to a dichotomo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['income'].replace({'<=50K':0,'>50K':1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_y = test_df['income']\n",
    "Test_y.replace({'<=50K.':0, '>50K.':1}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Delete useless features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('fnlwgt',axis=1)\n",
    "df = df.drop('education.num', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------Feature engineer--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. writen a custom transformer which will select the corresponding attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class featureSelector(BaseEstimator, TransformerMixin):\n",
    "  \n",
    "    def __init__(self, type):\n",
    "        self.type = type\n",
    "  \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return X.select_dtypes(include=[self.type])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Developed the numerical Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class array_df(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def _init_(self, name=['age', 'capital-gain', 'capital-loss', 'hours.per.week']):\n",
    "        self.names = name\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        d = pd.DataFrame(X, columns = ['age', 'capital-gain', 'capital-loss', 'hours.per.week'])\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(steps=[\n",
    "    (\"num_selector\", featureSelector(type='int')),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    ('arrayToDf', array_df())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete Numerical Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(steps=[\n",
    "    (\"num_selector\", featureSelector(type='int')),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    ('arrayToDf', array_df())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Developed the Categorical Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing the missing values with the most frequently occurring value in each column in the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalImputer(BaseEstimator, TransformerMixin):\n",
    "  \n",
    "    def __init__(self, columns = None, strategy='most_frequent'):\n",
    "        self.strategy = strategy\n",
    "        self.columns = columns\n",
    "    \n",
    "    \n",
    "    def fit(self,X, y=None):\n",
    "    \n",
    "        if self.strategy is 'most_frequent':\n",
    "            self.fill = {col: X[col].value_counts().index[0] for \n",
    "            col in self.columns}\n",
    "    \n",
    "        if self.columns is None:\n",
    "            self.columns = X.columns\n",
    "    \n",
    "        else:\n",
    "            self.fill ={col: '0' for col in self.columns}\n",
    "      \n",
    "        return self\n",
    "      \n",
    "    def transform(self,X):\n",
    "        X_2 = X.copy()\n",
    "        for col in self.columns:\n",
    "            X_2[col] = X_2[col].fillna(self.fill[col])\n",
    "        return X_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used pd.get_dummies to convert the categorical values to numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "  \n",
    "    def __init__(self, dropFirst=True):\n",
    "        self.categories = dict()\n",
    "        self.dropFirst = dropFirst\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        df_cat = df.select_dtypes(include=['object'])\n",
    "        for col in df_cat.columns:\n",
    "            self.categories[col] = df_cat[col].value_counts().index.tolist()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_2 = X.copy()\n",
    "        X_2 = X_2.select_dtypes(include=['object'])\n",
    "        for col in X_2.columns:\n",
    "            X_2[col] = X_2[col].astype({col: CategoricalDtype(self.categories[col])})\n",
    "            \n",
    "        return pd.get_dummies(X_2, drop_first=self.dropFirst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete Categorical Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline(steps=[\n",
    "    (\"cat_selector\", featureSelector(type='object')),\n",
    "    (\"cat_imputer\", CategoricalImputer(columns = ['occupation', 'workClass', 'native_country'])),\n",
    "    (\"cat_encoder\", CategoricalEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Split df to train data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_x = df[df['income'].notnull()].drop('income', axis=1)\n",
    "Train_y = df[df['income'].notnull()]['income']\n",
    "Test_x = df[df['income'].isnull()].drop('income', axis=1).reset_index(drop=True)\n",
    "Test_y = Test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Completed Pipeline uses pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_pipeline = FeatureUnion([(\"num_pipeline\", num_pipeline), \n",
    "#                 (\"cat_pipeline\", cat_pipeline)])\n",
    "\n",
    "Train_x_num = num_pipeline.fit_transform(Train_x)\n",
    "Train_x_cat = cat_pipeline.fit_transform(Train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.concat([Train_x_num, Train_x_cat, Train_y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_x_num = num_pipeline.fit_transform(Test_x)\n",
    "Test_x_cat = cat_pipeline.fit_transform(Test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = pd.concat([Test_x_num, Test_x_cat, Test_y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.to_csv('./data/Train_LR.csv',index=0)\n",
    "Test.to_csv('./data/Test_LR.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
